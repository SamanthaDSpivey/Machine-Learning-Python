{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Boosting is a meta-alogrithm since method can be applied to many types of ML alogrithms.\n",
    "  #Boosting iteratively improves learning of N models by giving greater weight to training cases w/ larger errors.\n",
    "    # Ensemble methods achieve better performance of weak machine learning algorithms (weak learners) by aggregating results of many statisically independent models.\n",
    "    # This process averages out errors & produces a final better prediction\n",
    "    # Simple Boosting procedure consists of:\n",
    "      # 1) N learners (machine learing models) are defined\n",
    "      # 2) Each of i training data cases is given an initial equal weight of 1/i\n",
    "      # 3) N learners are trained on weighted training data\n",
    "      # 4) Prediction is computed based on aggregatation of learners; averaging over hypthosis of N learners\n",
    "      # 5) Weights for training data cases are updated based on aggregated error made by learners. Cases w/ larger errors are given larger weights.\n",
    "      # 6) Steps 3, 4, 5 are reapeated until a convergence criteria is met.  \n",
    "    # Classification & regression tree models typically weak learners used w/ boosting.\n",
    "     # Adaptive boosting/AdaBoost is one of most successful boosted methods that uses some large #, N, tree models.\n",
    "       # The rate at which weights are updated is adaptive with the errors.\n",
    "    # Boosted ML is NOT robust to significant noise or outliers in training data. \n",
    "     # Reweighting process gives greater weight to large errors, & therefore can give undue weight to outliers & errors.\n",
    "     # When traing data cases are noisy, the random forest algorithm may prove to be more robust.\n",
    "    \n",
    "    \n",
    "#Import the packages to be used\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data previously prepared in data preparation step.\n",
    "\n",
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- There are 1000 cases w/ 35 features & 1 label. Numeric features wer Zscore scaled so they are 0 centered (mean removed) & unit variance (divide by std dev).\n",
    "\n",
    "#Below- Nested cross validation (Ncv) used to estimate optimal hyperparameters & perform model selection for AdaBoost tree model using 10 folds.\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Estimate best hyperparameters using 10 fold cv\n",
    " # 1) Grid of 1 hyperparameter is searched (intended to optimize level of regularization)\n",
    " #   # Learning_rate shrinks contribution of each classifer. THere is a trade-off b/w learning-rate & n_estimators.\n",
    " # 2) Class imbalance is true & difference in cost to bank for misclassification of bad credit risk customers\n",
    "     # will be addressed later.\n",
    " # 3) Model fit on each set of hyperparameters from grid\n",
    " # 4) Best estimated hyperparameters are displayed\n",
    "\n",
    "\n",
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}    ## Define dictionary for grid search & model object to search on\n",
    "\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  ## Define AdaBoosted tree model\n",
    "\n",
    "\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid,    ## Perform grid search over parameters\n",
    "                      cv = inside,          # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(Features, Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.758\n",
      "SDT of the Metric       = 0.034\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "# Perform outer cv of model\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of manitude smaller than mean, indicating this model will generalize well.\n",
    "\n",
    "#Below- Build & test model using estimated optimal hyperparameters\n",
    "\n",
    "nr.seed(1115)   # Randomly sample cases to create independent training & test data\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define AdaBoosted tree model object using estimated optimal hyperparameter & fit model to training data\n",
    "\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       176                36\n",
      "Actual Negative        45                43\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.76\n",
      "Macro Precision 0.67\n",
      "Macro Recall    0.66\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.80          0.54\n",
      "Recall       0.83          0.49\n",
      "F1           0.81          0.51\n"
     ]
    }
   ],
   "source": [
    "# Score & display performance metrics for test dataset model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ab_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 300]\n",
      "(600, 35)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "#Above- Performance metrics look poor. Large majority of negative (bad credit) cases are misclassified as positive.\n",
    "\n",
    "#Above- Performance metrics look good.Large majority of negative (bad credit) cases are identified at expense of significant fp.\n",
    "  # This shows AdaBoosted method are sensitive to class imbalance.\n",
    "    \n",
    "#Below- Poor performance is more than likely due to class imbalance & unable to reweigh classes w/ boosting methods. Alternatives:\n",
    " # 1) Impute new values using statistical alogrithm\n",
    " # 2) Undersample majority of cases. For this method, a # of cases = to minority case are Bernoulli sampled from majority case.\n",
    " # 3) Oversampl minority cases. For this method, a # of minority cases are resampled until = # of majority cases.\n",
    "    \n",
    "# Undersample the majority cases (good credit customers), using choice funtion from Numpy.random package to randomize undersampling.\n",
    " # Count of unique label values & shape of resulting arrays is displayed.\n",
    " # Create data set w/ balanced cases.\n",
    "\n",
    "temp_Labels_1 = Labels[Labels == 1]         # Save these\n",
    "temp_Features_1 = Features[Labels == 1,:]    # Save these\n",
    "temp_Labels_0 = Labels[Labels == 0]        # Undersample these\n",
    "temp_Features_0 = Features[Labels == 0,:]    # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "temp_Features = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "temp_Labels = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(temp_Labels))\n",
    "print(temp_Features.shape)\n",
    "print(temp_Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "#Above- Now 300 of each label case w/ 600 cases overall.\n",
    "\n",
    "#Below- Perform model selection again w/ ncv\n",
    " #Compute inner loop to find optimal learning rate parameter\n",
    "    \n",
    "nr.seed(1234)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(3214)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "ab_clf = AdaBoostClassifier()    # Define AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid,    # Perform grid search over parameters\n",
    "                      cv = inside,                     # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(temp_Features, temp_Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.758\n",
      "SDT of the Metric       = 0.034\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "#Above- Estimated optimal learning rate parameter is small (0.1) than before (1).\n",
    "\n",
    "#Below- Perform outer cv of model\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212 212]\n",
      "(424, 35)\n",
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "#Above- Average AUC is improved compared to imbalanced training cases. Differences are w/in 1 std dev. Still reasonable chance represent improvement.\n",
    "\n",
    "#Below- Train & evaluate model w/ balanced cases & updated hyperparameter.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "  # Define AdaBoosted model\n",
    "  # Train AdaBoosted model\n",
    "    \n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])   # Randomly sample cases to create independent training & test data\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])\n",
    "\n",
    "# Undersample majority case for training data\n",
    "temp_Labels_1 = y_train[y_train == 1]      # Save these\n",
    "temp_Features_1 = x_train[y_train == 1,:]      # Save these\n",
    "temp_Labels_0 = y_train[y_train == 0]       # Undersample these\n",
    "temp_Features_0 = x_train[y_train == 0,:]     # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "x_train = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "y_train = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.1, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define & fit the model\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       146                66\n",
      "Actual Negative        19                69\n",
      "\n",
      "Accuracy        0.72\n",
      "AUC             0.79\n",
      "Macro Precision 0.70\n",
      "Macro Recall    0.74\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.88          0.51\n",
      "Recall       0.69          0.78\n",
      "F1           0.77          0.62\n"
     ]
    }
   ],
   "source": [
    "# Score & evaluate the model\n",
    "\n",
    "probabilities = ab_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Results are significantly better than previously obtained imbalanced training data in classifying negative cases.\n",
    "  # AUC is more than 1 std dev away from ncv AUC.\n",
    "    \n",
    "## Summary\n",
    "  # 1) Used 10 fold to find estimated optimal hyperparameters for AdaBoosted tree model to classify credit risk cases. \n",
    "      # Model did not generalize well due to class imbalance.\n",
    "  # 2) Applied undersampling of majority cases to create balanced training dataset & retrained & evaluated model.\n",
    "      # Model created w/ balanced training data was significantly better.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
