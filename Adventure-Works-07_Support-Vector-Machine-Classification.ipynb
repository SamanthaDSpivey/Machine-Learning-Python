{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Goal: Explore data w/ visualizations for Adventure Works dataset \n",
    "      #    for purpose of Classification Supervised ML w/ label= BikeBuyer\n",
    "\n",
    "# Import Python pkgs pandas, numpy, matplotlib.pyplot, & seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn import cross_validation\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import metrics, cross_validation, svm\n",
    "import scipy.stats as ss\n",
    "import sklearn.decomposition as skde\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline  \n",
    "# Start of magic command which configures execution environment, to display graphics w/in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>City</th>\n",
       "      <th>StateProvinceName</th>\n",
       "      <th>CountryRegionName</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PhoneNumber</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>YearlyIncome</th>\n",
       "      <th>Age</th>\n",
       "      <th>AveMonthSpend</th>\n",
       "      <th>BikeBuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jon</td>\n",
       "      <td>Yang</td>\n",
       "      <td>3761 N. 14th St</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4700</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>4/8/1966</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>137947</td>\n",
       "      <td>31</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eugene</td>\n",
       "      <td>Huang</td>\n",
       "      <td>2243 W St.</td>\n",
       "      <td>Seaford</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>3198</td>\n",
       "      <td>1 (11) 500 555-0110</td>\n",
       "      <td>5/14/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>101141</td>\n",
       "      <td>32</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruben</td>\n",
       "      <td>Torres</td>\n",
       "      <td>5844 Linden Land</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7001</td>\n",
       "      <td>1 (11) 500 555-0184</td>\n",
       "      <td>8/12/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91945</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>1825 Village Pl.</td>\n",
       "      <td>North Ryde</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2113</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>2/15/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86688</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>7553 Harness Circle</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2500</td>\n",
       "      <td>1 (11) 500 555-0131</td>\n",
       "      <td>8/8/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92771</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstName LastName         AddressLine1         City StateProvinceName  \\\n",
       "0        Jon     Yang      3761 N. 14th St  Rockhampton        Queensland   \n",
       "1     Eugene    Huang           2243 W St.      Seaford          Victoria   \n",
       "2      Ruben   Torres     5844 Linden Land       Hobart          Tasmania   \n",
       "3    Christy      Zhu     1825 Village Pl.   North Ryde   New South Wales   \n",
       "4  Elizabeth  Johnson  7553 Harness Circle   Wollongong   New South Wales   \n",
       "\n",
       "  CountryRegionName PostalCode          PhoneNumber  BirthDate   Education  \\\n",
       "0         Australia       4700  1 (11) 500 555-0162   4/8/1966  Bachelors    \n",
       "1         Australia       3198  1 (11) 500 555-0110  5/14/1965  Bachelors    \n",
       "2         Australia       7001  1 (11) 500 555-0184  8/12/1965  Bachelors    \n",
       "3         Australia       2113  1 (11) 500 555-0162  2/15/1968  Bachelors    \n",
       "4         Australia       2500  1 (11) 500 555-0131   8/8/1968  Bachelors    \n",
       "\n",
       "     ...     Gender MaritalStatus HomeOwnerFlag  NumberCarsOwned  \\\n",
       "0    ...          M             M             1                0   \n",
       "1    ...          M             S             0                1   \n",
       "2    ...          M             M             1                1   \n",
       "3    ...          F             S             0                1   \n",
       "4    ...          F             S             1                4   \n",
       "\n",
       "   NumberChildrenAtHome  TotalChildren  YearlyIncome  Age  AveMonthSpend  \\\n",
       "0                     0              2        137947   31             89   \n",
       "1                     3              3        101141   32            117   \n",
       "2                     3              3         91945   32            123   \n",
       "3                     0              0         86688   29             50   \n",
       "4                     5              5         92771   29             95   \n",
       "\n",
       "   BikeBuyer  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load already prepared dataset, display shape, & explore first 10 rows of Pandas data frame\n",
    "\n",
    "AW_Custs_C = pd.read_csv('AdvWorksCusts_Preped.csv', header=0)\n",
    "print(AW_Custs_C.shape)\n",
    "AW_Custs_C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10949\n",
      "1     5455\n",
      "Name: BikeBuyer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Testing for Class Imbalance by Examining Classes where label= BikeBuyer\n",
    " # Unequal numbers of cases for the categories of labels, which can seriously bias the training of classifier alogrithms \n",
    " #  higher error rate for the minority class. This should be tested for before training any model.   \n",
    "\n",
    "AW_Custs_C_counts =  AW_Custs_C['BikeBuyer'].value_counts()\n",
    "print(AW_Custs_C_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Knowing imbalance exists, the best accuracy we can get w/out creating a ML model is 70%.\n",
    " # This is achieved by guessing all customers will buy a bike\n",
    "    \n",
    "#Below- Create a numpy array of label values\n",
    "\n",
    "labels = np.array(AW_Custs_C['BikeBuyer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 31)\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Create a numpy array with all of the features (Model Matrix)\n",
    " # Encode categorical string variables into integers. \n",
    " # Transform integer coded variables to dummy variables.\n",
    " # Append each dummy coded categorical variable to model matrix.\n",
    "    \n",
    "def encode_string(cat_features):\n",
    "    enc = preprocessing.LabelEncoder()  # Encode strings to numeric categories\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    \n",
    "    ohe = preprocessing.OneHotEncoder()  #Apply One Hot Encoder\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Education', 'Gender', 'MaritalStatus', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren']\n",
    "\n",
    "Features = encode_string(AW_Custs_C['Occupation'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AW_Custs_C[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "    \n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 33)\n",
      "[[0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.37947e+05 3.10000e+01]\n",
      " [0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.01141e+05 3.20000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Append numeric features to model matrix\n",
    "\n",
    "Features = np.concatenate([Features, np.array(AW_Custs_C[['YearlyIncome', 'Age']])], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Professional' 'Management' 'Skilled Manual' 'Clerical' 'Manual']\n"
     ]
    }
   ],
   "source": [
    "# 6 categorical variables were converted into 31 dummy variables. \n",
    "\n",
    "#Below- How many dummy variables came from checking_account_status? -5-\n",
    "print(AW_Custs_C['Occupation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Below- Perform model selection w/ nested cross validation (ncv) for optimal hyperparameters & model selection.\n",
    " # Compute inner loop to find optimal learning rate parameter w/ 5 fold cv since training SVM is computationally intensive.\n",
    "   # Additional folds would give better estimates but at cost of greater computation time.\n",
    "\n",
    "# Define inside & outer folds\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=5, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Estimate optimal hyperparameters using 5 fold cv.\n",
    " # In interest of computational efficiency, values for only 2 parameters will be searched.\n",
    "  #1) Grid of 2 hyperparameters:\n",
    "  #   A) C- is inverse of lamda of l2 regularization hyperparameter\n",
    "  #   B) gamma- span of RBF kernel\n",
    "  #2) Class weights are used due to class imbalance & difference in cost to bank of misclassification of bad credit risk customers\n",
    "  #3) Model is fit on grid & best estimated hyperparameters are displayed\n",
    "\n",
    "nr.seed(3456)\n",
    "\n",
    "param_grid = {\"C\": [1, 10, 100, 1000], \"gamma\":[1.0/50.0, 1.0/200.0, 1.0/500.0, 1.0/1000.0]}   # Define dictionary for grid search & model object to search on\n",
    "svc_clf = svm.SVC(class_weight = {0:0.33, 1:0.67})    # Define SVM model\n",
    "\n",
    "clf = ms.GridSearchCV(estimator = svc_clf, param_grid = param_grid,    # Perform grid search over parameters\n",
    "                      cv = inside,                       # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, labels)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.597\n",
      "SDT of the Metric       = 0.007\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.598\n",
      "Fold  2    0.604\n",
      "Fold  3    0.605\n",
      "Fold  4    0.591\n",
      "Fold  5    0.587\n"
     ]
    }
   ],
   "source": [
    "#Above- Estimated optimal learning rate parameters are C=1, & gamma=0.001.\n",
    "\n",
    "#Below- Perform outer cv of model.\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, labels, \n",
    "                                 cv = outside)       # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of magnitude smaller than mean itself, indicating that this model is likely to generalize well, but level of performance is unclear.\n",
    "\n",
    "#Below- Build, train & evaluate model w/ estimated optimal hyperparameters.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])    # Randomly sample cases to create independent training & test data\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight={0: 0.33, 1: 0.67}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define rbf SVM model object w/ optimal hyperparmeters & fit model to training data subset\n",
    "\n",
    "nr.seed(1115)\n",
    "svm_mod = svm.SVC(C = clf.best_estimator_.C,\n",
    "                  gamma = clf.best_estimator_.gamma,\n",
    "                  class_weight = {0:0.33, 1:0.67},\n",
    "                  probability=True) \n",
    "svm_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive      3317                 0\n",
      "Actual Negative      1683                 0\n",
      "\n",
      "Accuracy        0.66\n",
      "AUC             0.59\n",
      "Macro Precision 0.33\n",
      "Macro Recall    0.50\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case     3317          1683\n",
      "Precision    0.66          0.00\n",
      "Recall       1.00          0.00\n",
      "F1           0.80          0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samantha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Above- Hyperparameters of rbf SVM model object are as expected. \n",
    "\n",
    "#Below- Score & evaluate the test model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = svm_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Performance of the rbf SVM above is acceptable.\n",
    "  # Large majority of high risk customers are identified, but at cost of large # of FP & low precision for negative cases.\n",
    "  # AUC= 0.80 is better than mean achieved w/ 5 fold cv.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
