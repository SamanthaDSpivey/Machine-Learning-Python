{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes (nb) Models make the naive assumption of statisitcal independence of features\n",
    "  # Surprisingly effective despite violating assumption of indenpendence. A useful & effective simplification of general Bayesian models.\n",
    "  # Use empirical distributions of features to compute probabilities of labels & can use most any family of distributions for features.\n",
    "  # Important to select correct distribution family for data you are working with.\n",
    "    # Gaussian- for continuous or numerical features\n",
    "    # Bernoulli- features w/ binary features\n",
    "    # Multinomial- feature w/ more than 2 categories\n",
    "  # Pitfall- model fails if 0 probability is encountered, which occurs when there's a 'hole' in smpl space where there are no smpls.\n",
    "    # Simple smoothing hyperparameter, alpha, can deal w/ this problem & is one of few required for nb models. \n",
    "  # Computational complexity is linear in # of parameters/features, making nb highly scalable. There are out or core approaches suitable for masive datasets.\n",
    "  # Requires minimal data to produce models that generalizes well.\n",
    "    # If only a few cases per category to train model, a nb model can be a good choice.\n",
    "  # Have simple & inherent regularization\n",
    "  # NB used in:\n",
    "    # document classification\n",
    "    # SPAM detection\n",
    "    # Image classification\n",
    "    \n",
    "#Import the packages to be used\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data previously prepared in data preparation step.\n",
    "\n",
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.691\n",
      "SDT of the Metric       = 0.093\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.720\n",
      "Fold  2    0.660\n",
      "Fold  3    0.770\n",
      "Fold  4    0.690\n",
      "Fold  5    0.750\n",
      "Fold  6    0.430\n",
      "Fold  7    0.690\n",
      "Fold  8    0.760\n",
      "Fold  9    0.710\n",
      "Fold 10    0.730\n"
     ]
    }
   ],
   "source": [
    "#Above- There are 1000 cases w/ 35 features & 1 label. Numeric features wer Zscore scaled so they are 0 centered (mean removed) & unit variance (divide by std dev).\n",
    "\n",
    "#Below- Features array has both numeric & binary features (dummy variables for categorical features)\n",
    "  # Therefore, Gaussian model must be used, however it's not ideal since numeric features mixed w/ features exhibiting Bernoulli distributions (binary features)\n",
    "  \n",
    "\n",
    "nr.seed(321)\n",
    "cv_folds = ms.KFold(n_splits=10, shuffle = True)  #Define 10 fold cv object\n",
    "    \n",
    "nr.seed(498)\n",
    "NB_credit = GaussianNB()      #Define Gaussian naive Bayes model\n",
    "cv_estimate = ms.cross_val_score(NB_credit, Features, Labels,     #Performs 10 fold cv\n",
    "                                 cv = cv_folds)       # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))    # Display cv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of magnitude smaller than mean itself, indicating that this model is likely to generalize well, but level of performance is unclear.\n",
    "\n",
    "#Below- Build, train & evaluate model w/ estimated optimal hyperparameters.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define G-nb model object & fit model to training data subset\n",
    "\n",
    "NB_credit_mod = GaussianNB() \n",
    "NB_credit_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive        30               182\n",
      "Actual Negative         6                82\n",
      "\n",
      "Accuracy        0.37\n",
      "AUC             0.69\n",
      "Macro Precision 0.57\n",
      "Macro Recall    0.54\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.83          0.31\n",
      "Recall       0.14          0.93\n",
      "F1           0.24          0.47\n"
     ]
    }
   ],
   "source": [
    "#Below- Score & evaluate the test model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Above- Performance of the G-nb above is poor.\n",
    "  # Barely half bad credit risk customer correctly identified.\n",
    "  # AUC= 0.69 is quite a bit better than mean achieved w/ 5 fold cv. Likely these figures are optimistic.\n",
    "\n",
    "#Below- Check if Bernoulli naive Bayes (B-nb) model is better, since less sensitive to quantity of training data.\n",
    "  # First remove numeric features from array & examine results.\n",
    "    \n",
    "Features = Features[:,4:]\n",
    "Features[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform model selection w/ nested cross validation (ncv) for optimal hyperparameters & model selection.\n",
    " # Compute inner loop to find optimal learning rate parameter w/ 10 fold cv.\n",
    "   # Additional folds would give better estimates but at cost of greater computation time.\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Estimate optimal hyperparameters using 10 fold cv.\n",
    "  #1) Grid of 1 hyperparameter:\n",
    "  #   A) alpha- smoothing parameter to avoid 0 possibilities.\n",
    "  #2) Model is fit on grid & best estimated hyperparameters are displayed\n",
    "\n",
    "nr.seed(3456)\n",
    "param_grid = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}    # Define dictionary for grid search & model object to search on\n",
    "NB_clf = BernoulliNB()   # Define B-NB regression model\n",
    "\n",
    "clf = ms.GridSearchCV(estimator = NB_clf, param_grid = param_grid,   # Perform grid search over 1 parameter\n",
    "                      cv = inside,                 # Use inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, Labels)\n",
    "print(clf.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.754\n",
      "SDT of the Metric       = 0.040\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.735\n",
      "Fold  2    0.701\n",
      "Fold  3    0.733\n",
      "Fold  4    0.745\n",
      "Fold  5    0.771\n",
      "Fold  6    0.757\n",
      "Fold  7    0.762\n",
      "Fold  8    0.857\n",
      "Fold  9    0.765\n",
      "Fold 10    0.713\n"
     ]
    }
   ],
   "source": [
    "#Above- Estimated optimal learning rate parameters are alpha= 1.\n",
    "  # Indicates, there is very little problem w/ 0 probabilities in this problem, resulting from the fact that probability space sampld is dense.\n",
    "\n",
    "#Below- Perform outer cv of model to estimate model performance w/ optimal hyperparameters.\n",
    "\n",
    "#NB_credit = BernoulliNB(alpha = clf.best_estimator_.alpha)\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, Labels, \n",
    "                                 cv = outside)              # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC (acceptable) is an order of magnitude less than mean itself.\n",
    "\n",
    "#Below- Build, train & evaluate model w/ estimated optimal hyperparameters.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])      # Randomly sample cases to create independent training & test data\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       178                34\n",
      "Actual Negative        34                54\n",
      "\n",
      "Accuracy        0.77\n",
      "AUC             0.78\n",
      "Macro Precision 0.73\n",
      "Macro Recall    0.73\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.84          0.61\n",
      "Recall       0.84          0.61\n",
      "F1           0.84          0.61\n"
     ]
    }
   ],
   "source": [
    "# Define B-nb model object w/ optimal hyperparmeters & fit model to training data subset\n",
    "\n",
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha) \n",
    "NB_credit_mod.fit(x_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       116                96\n",
      "Actual Negative        17                71\n",
      "\n",
      "Accuracy        0.62\n",
      "AUC             0.78\n",
      "Macro Precision 0.65\n",
      "Macro Recall    0.68\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.87          0.43\n",
      "Recall       0.55          0.81\n",
      "F1           0.67          0.56\n"
     ]
    }
   ],
   "source": [
    "#Above- Performance of the B-nb is much better than G-nb, but still could be better.\n",
    "  # Current model uses empirical distribution of label values for prior value of p of Bernoulli distribution.\n",
    "   # This probability is invariably skewed toward majority case, setting this distribution to a fixed prior value can help overcome class imbalance.\n",
    "\n",
    "#Below- Redefine model object w/ prior probability of 0.6 for minority case.\n",
    "\n",
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha,\n",
    "                            class_prior = [0.4,0.6]) \n",
    "NB_credit_mod.fit(x_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- \n",
    "  # Large majority of high risk (bad credit) customers are identified, but at cost of large # of FP error rate.\n",
    "  # False negative is 5* the cost of FP, this may be good solution.\n",
    "  # Inifinte # of other models are possible by changing the prior distribution.\n",
    "\n",
    "## Summary- \n",
    "  # 1) Fit Gaussian naive Bayes model on bank credit data.\n",
    "      # Performance of this model was poor as result of many Bernoulli distributed dummy features.\n",
    "  # 2) Used Bernoulli naive Bayes model for bank credit data by eliminating numeric values. \n",
    "      # Overall, this model was much better.\n",
    "  # 3) A model skewed toward detecting bad credit cases was created using prior distribution rather than empirical distribution of labels.\n",
    "      # This model correctly classified significant # of bad credit cases. Selecting other prior distributions will give other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
