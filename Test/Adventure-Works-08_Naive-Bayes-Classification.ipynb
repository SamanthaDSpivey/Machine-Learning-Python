{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samantha\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Goal: Explore data w/ visualizations for Adventure Works dataset \n",
    "      #    for purpose of Classification Supervised ML w/ label= BikeBuyer\n",
    "\n",
    "# Import Python pkgs pandas, numpy, matplotlib.pyplot, & seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn import cross_validation\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import metrics, cross_validation\n",
    "import scipy.stats as ss\n",
    "import sklearn.decomposition as skde\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "%matplotlib inline  \n",
    "# Start of magic command which configures execution environment, to display graphics w/in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>City</th>\n",
       "      <th>StateProvinceName</th>\n",
       "      <th>CountryRegionName</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PhoneNumber</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>YearlyIncome</th>\n",
       "      <th>Age</th>\n",
       "      <th>AveMonthSpend</th>\n",
       "      <th>BikeBuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jon</td>\n",
       "      <td>Yang</td>\n",
       "      <td>3761 N. 14th St</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4700</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>4/8/1966</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>137947</td>\n",
       "      <td>31</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eugene</td>\n",
       "      <td>Huang</td>\n",
       "      <td>2243 W St.</td>\n",
       "      <td>Seaford</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>3198</td>\n",
       "      <td>1 (11) 500 555-0110</td>\n",
       "      <td>5/14/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>101141</td>\n",
       "      <td>32</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruben</td>\n",
       "      <td>Torres</td>\n",
       "      <td>5844 Linden Land</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7001</td>\n",
       "      <td>1 (11) 500 555-0184</td>\n",
       "      <td>8/12/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91945</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>1825 Village Pl.</td>\n",
       "      <td>North Ryde</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2113</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>2/15/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86688</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>7553 Harness Circle</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2500</td>\n",
       "      <td>1 (11) 500 555-0131</td>\n",
       "      <td>8/8/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92771</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstName LastName         AddressLine1         City StateProvinceName  \\\n",
       "0        Jon     Yang      3761 N. 14th St  Rockhampton        Queensland   \n",
       "1     Eugene    Huang           2243 W St.      Seaford          Victoria   \n",
       "2      Ruben   Torres     5844 Linden Land       Hobart          Tasmania   \n",
       "3    Christy      Zhu     1825 Village Pl.   North Ryde   New South Wales   \n",
       "4  Elizabeth  Johnson  7553 Harness Circle   Wollongong   New South Wales   \n",
       "\n",
       "  CountryRegionName PostalCode          PhoneNumber  BirthDate   Education  \\\n",
       "0         Australia       4700  1 (11) 500 555-0162   4/8/1966  Bachelors    \n",
       "1         Australia       3198  1 (11) 500 555-0110  5/14/1965  Bachelors    \n",
       "2         Australia       7001  1 (11) 500 555-0184  8/12/1965  Bachelors    \n",
       "3         Australia       2113  1 (11) 500 555-0162  2/15/1968  Bachelors    \n",
       "4         Australia       2500  1 (11) 500 555-0131   8/8/1968  Bachelors    \n",
       "\n",
       "     ...     Gender MaritalStatus HomeOwnerFlag  NumberCarsOwned  \\\n",
       "0    ...          M             M             1                0   \n",
       "1    ...          M             S             0                1   \n",
       "2    ...          M             M             1                1   \n",
       "3    ...          F             S             0                1   \n",
       "4    ...          F             S             1                4   \n",
       "\n",
       "   NumberChildrenAtHome  TotalChildren  YearlyIncome  Age  AveMonthSpend  \\\n",
       "0                     0              2        137947   31             89   \n",
       "1                     3              3        101141   32            117   \n",
       "2                     3              3         91945   32            123   \n",
       "3                     0              0         86688   29             50   \n",
       "4                     5              5         92771   29             95   \n",
       "\n",
       "   BikeBuyer  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load already prepared dataset, display shape, & explore first 10 rows of Pandas data frame\n",
    "\n",
    "AW_Custs_C = pd.read_csv('AdvWorksCusts_Preped.csv', header=0)\n",
    "print(AW_Custs_C.shape)\n",
    "AW_Custs_C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10949\n",
      "1     5455\n",
      "Name: BikeBuyer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Testing for Class Imbalance by Examining Classes where label= BikeBuyer\n",
    " # Unequal numbers of cases for the categories of labels, which can seriously bias the training of classifier alogrithms \n",
    " #  higher error rate for the minority class. This should be tested for before training any model.   \n",
    "\n",
    "AW_Custs_C_counts =  AW_Custs_C['BikeBuyer'].value_counts()\n",
    "print(AW_Custs_C_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Knowing imbalance exists, the best accuracy we can get w/out creating a ML model is 70%.\n",
    " # This is achieved by guessing all customers will buy a bike\n",
    "    \n",
    "#Below- Create a numpy array of label values\n",
    "\n",
    "labels = np.array(AW_Custs_C['BikeBuyer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 31)\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Create a numpy array with all of the features (Model Matrix)\n",
    " # Encode categorical string variables into integers. \n",
    " # Transform integer coded variables to dummy variables.\n",
    " # Append each dummy coded categorical variable to model matrix.\n",
    "    \n",
    "def encode_string(cat_features):\n",
    "    enc = preprocessing.LabelEncoder()  # Encode strings to numeric categories\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    \n",
    "    ohe = preprocessing.OneHotEncoder()  #Apply One Hot Encoder\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Education', 'Gender', 'MaritalStatus', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren']\n",
    "\n",
    "Features = encode_string(AW_Custs_C['Occupation'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AW_Custs_C[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "    \n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 33)\n",
      "[[0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.37947e+05 3.10000e+01]\n",
      " [0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.01141e+05 3.20000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Append numeric features to model matrix\n",
    "\n",
    "Features = np.concatenate([Features, np.array(AW_Custs_C[['YearlyIncome', 'Age']])], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Professional' 'Management' 'Skilled Manual' 'Clerical' 'Manual']\n"
     ]
    }
   ],
   "source": [
    "# 6 categorical variables were converted into 31 dummy variables. \n",
    "\n",
    "#Below- How many dummy variables came from checking_account_status? -5-\n",
    "print(AW_Custs_C['Occupation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.742\n",
      "SDT of the Metric       = 0.009\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.763\n",
      "Fold  2    0.728\n",
      "Fold  3    0.745\n",
      "Fold  4    0.747\n",
      "Fold  5    0.735\n",
      "Fold  6    0.733\n",
      "Fold  7    0.738\n",
      "Fold  8    0.748\n",
      "Fold  9    0.741\n",
      "Fold 10    0.738\n"
     ]
    }
   ],
   "source": [
    "#Below- Features array has both numeric & binary features (dummy variables for categorical features)\n",
    "  # Therefore, Gaussian model must be used, however it's not ideal since numeric features mixed w/ features exhibiting Bernoulli distributions (binary features)\n",
    "  \n",
    "\n",
    "nr.seed(321)\n",
    "cv_folds = ms.KFold(n_splits=10, shuffle = True)  #Define 10 fold cv object\n",
    "    \n",
    "nr.seed(498)\n",
    "NB_credit = GaussianNB()      #Define Gaussian naive Bayes model\n",
    "cv_estimate = ms.cross_val_score(NB_credit, Features, labels,     #Performs 10 fold cv\n",
    "                                 cv = cv_folds)       # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))    # Display cv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of magnitude smaller than mean itself, indicating that this model is likely to generalize well, but level of performance is unclear.\n",
    "\n",
    "#Below- Build, train & evaluate model w/ estimated optimal hyperparameters.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define G-nb model object & fit model to training data subset\n",
    "\n",
    "NB_credit_mod = GaussianNB() \n",
    "NB_credit_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive      3044               273\n",
      "Actual Negative      1054               629\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.80\n",
      "Macro Precision 0.72\n",
      "Macro Recall    0.65\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case     3317          1683\n",
      "Precision    0.74          0.70\n",
      "Recall       0.92          0.37\n",
      "F1           0.82          0.49\n"
     ]
    }
   ],
   "source": [
    "#Below- Score & evaluate the test model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.37947e+05, 3.10000e+01],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.01141e+05, 3.20000e+01],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 9.19450e+04, 3.20000e+01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Above- Performance of the G-nb above is ideal.\n",
    "  # Barely half bad credit risk customer correctly identified.\n",
    "  # AUC= 0.80 is quite a bit better than mean achieved w/ 5 fold cv. Likely these figures are optimistic.\n",
    "\n",
    "#Below- Check if Bernoulli naive Bayes (B-nb) model is better, since less sensitive to quantity of training data.\n",
    "  # First remove numeric features from array & examine results.\n",
    "    \n",
    "Features = Features[:,4:]\n",
    "Features[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform model selection w/ nested cross validation (ncv) for optimal hyperparameters & model selection.\n",
    " # Compute inner loop to find optimal learning rate parameter w/ 10 fold cv.\n",
    "   # Additional folds would give better estimates but at cost of greater computation time.\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Estimate optimal hyperparameters using 10 fold cv.\n",
    "  #1) Grid of 1 hyperparameter:\n",
    "  #   A) alpha- smoothing parameter to avoid 0 possibilities.\n",
    "  #2) Model is fit on grid & best estimated hyperparameters are displayed\n",
    "\n",
    "nr.seed(3456)\n",
    "param_grid = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}    # Define dictionary for grid search & model object to search on\n",
    "NB_clf = BernoulliNB()   # Define B-NB regression model\n",
    "\n",
    "clf = ms.GridSearchCV(estimator = NB_clf, param_grid = param_grid,   # Perform grid search over 1 parameter\n",
    "                      cv = inside,                 # Use inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, labels)\n",
    "print(clf.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.796\n",
      "SDT of the Metric       = 0.007\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.807\n",
      "Fold  2    0.790\n",
      "Fold  3    0.796\n",
      "Fold  4    0.800\n",
      "Fold  5    0.788\n",
      "Fold  6    0.796\n",
      "Fold  7    0.798\n",
      "Fold  8    0.803\n",
      "Fold  9    0.784\n",
      "Fold 10    0.798\n"
     ]
    }
   ],
   "source": [
    "#Above- Estimated optimal learning rate parameters are alpha= 10.\n",
    "  # Indicates, there is very little problem w/ 0 probabilities in this problem, resulting from the fact that probability space sampld is dense.\n",
    "\n",
    "#Below- Perform outer cv of model to estimate model performance w/ optimal hyperparameters.\n",
    "\n",
    "#NB_credit = BernoulliNB(alpha = clf.best_estimator_.alpha)\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, labels, \n",
    "                                 cv = outside)              # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC (acceptable) is an order of magnitude less than mean itself.\n",
    "\n",
    "#Below- Build, train & evaluate model w/ estimated optimal hyperparameters.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])      # Randomly sample cases to create independent training & test data\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive      2847               470\n",
      "Actual Negative       696               987\n",
      "\n",
      "Accuracy        0.77\n",
      "AUC             0.80\n",
      "Macro Precision 0.74\n",
      "Macro Recall    0.72\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case     3317          1683\n",
      "Precision    0.80          0.68\n",
      "Recall       0.86          0.59\n",
      "F1           0.83          0.63\n"
     ]
    }
   ],
   "source": [
    "# Define B-nb model object w/ optimal hyperparmeters & fit model to training data subset\n",
    "\n",
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha) \n",
    "NB_credit_mod.fit(x_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive      2461               856\n",
      "Actual Negative       499              1184\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.80\n",
      "Macro Precision 0.71\n",
      "Macro Recall    0.72\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case     3317          1683\n",
      "Precision    0.83          0.58\n",
      "Recall       0.74          0.70\n",
      "F1           0.78          0.64\n"
     ]
    }
   ],
   "source": [
    "#Above- Performance of the B-nb is much better than G-nb, but still could be better.\n",
    "  # Current model uses empirical distribution of label values for prior value of p of Bernoulli distribution.\n",
    "   # This probability is invariably skewed toward majority case, setting this distribution to a fixed prior value can help overcome class imbalance.\n",
    "\n",
    "#Below- Redefine model object w/ prior probability of 0.6 for minority case.\n",
    "\n",
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha,\n",
    "                            class_prior = [0.4,0.6]) \n",
    "NB_credit_mod.fit(x_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- \n",
    "  # Large majority of non bike buyer/customers are identified, but at cost of large # of FP error rate.\n",
    "  # Inifinte # of other models are possible by changing the prior distribution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
