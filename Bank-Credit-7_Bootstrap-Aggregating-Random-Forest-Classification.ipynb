{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bootstrap Aggregation (Bagging) is a widely used ensemble method\n",
    "    # Ensemble methods achieve better performance of weak machine learning algorithms (weak learners) by aggregating results of many statisically independent models.\n",
    "    # This process averages out errors & produces a final better prediction\n",
    "    # Simple procedure consists of:\n",
    "      # 1) N learners (machine learing models) are defined\n",
    "      # 2) N subsamples of the training data are created by Bernoulli sampling w/ replacement\n",
    "      # 3) N learners are trained on subsamples of training data\n",
    "      # 4) Ensemble is scored by averaging, or taking amjority vote, of predictions from N learners\n",
    "    # Claissification & regression tree models typically used w/ bagging, such as Random Forest.\n",
    "     # Random forest (rf) is highly scalable & generally produces good results, even for complex problems\n",
    "     # Tend to be robust to noise or outliers in training data, & true for rf as well.\n",
    "\n",
    "    \n",
    "#Import the packages to be used\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data previously prepared in data preparation step.\n",
    "\n",
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- There are 1000 cases w/ 35 features & 1 label. Numeric features wer Zscore scaled so they are 0 centered (mean removed) & unit variance (divide by std dev).\n",
    "\n",
    "#Below- Nested cross validation (cv) used to estimate optimal hyperparameters & perform model selection for rf model using 10 folds.\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Estimate best hyperparameters using 10 fold cv\n",
    " # 1) Grid of 2 hyperparameters are searched (intended to optimize level of regularization)\n",
    " #   A) max_Features- determines max # of features used to determine splits. \n",
    " #         Minimizing # of features can prevent model over-fitting by induced bias.\n",
    " #   B) min_samples_leaf- determines min # of smpls/leaves which must be on terminal node of tree.\n",
    " #         Maintaining min # of smpls per terminal node (a regularization method) allows model training to memorize data if too few.\n",
    " #         Biased predictions can result if too many smpls on terminal nodes.\n",
    " # 2) \"balanced\" argument is used since class imbalance & differencein cost to bank for misclassification of bad credit risk customers.\n",
    " #      Each tree will have balanced case subsets for training\n",
    " # 3) Model fit on each set of hyperparameters from grid\n",
    " # 4) Best estimated hyperparameters are displayed\n",
    "\n",
    "\n",
    "param_grid = {\"max_features\": [2, 3, 5, 10, 15], \"min_samples_leaf\":[3, 5, 10, 20]}    # Define dictionary for grid search & model object to search on\n",
    "\n",
    "nr.seed(3456)\n",
    "rf_clf = RandomForestClassifier(class_weight = \"balanced\")   # Define random forest model w/ class_weight = {0:0.33, 1:0.67}) \n",
    "\n",
    "nr.seed(4455)\n",
    "rf_clf = ms.GridSearchCV(estimator = rf_clf, param_grid = param_grid,    # Perform grid search over parameters\n",
    "                      cv = inside,                                       # Use inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "rf_clf.fit(Features, Labels)\n",
    "print(rf_clf.best_estimator_.max_features)\n",
    "print(rf_clf.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.762\n",
      "SDT of the Metric       = 0.038\n",
      "Outcomes by cv Fold\n",
      "Fold  1    0.754\n",
      "Fold  2    0.717\n",
      "Fold  3    0.733\n",
      "Fold  4    0.724\n",
      "Fold  5    0.787\n",
      "Fold  6    0.825\n",
      "Fold  7    0.743\n",
      "Fold  8    0.828\n",
      "Fold  9    0.776\n",
      "Fold 10    0.731\n"
     ]
    }
   ],
   "source": [
    "# Perform outer cv of model\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(rf_clf, Features, Labels, \n",
    "                                 cv = outside)              # Use outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of manitude smaller than mean, indicating this model will generalize well.\n",
    "\n",
    "#Below- Build & test model using estimated optimal hyperparameters\n",
    "\n",
    "nr.seed(1115)   # Randomly sample cases to create independent training & test data\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features=3,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=20,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define rf model object using estimated optimal hyperparameter & fit model to training data\n",
    "\n",
    "nr.seed(1115)\n",
    "rf_mod = RandomForestClassifier(class_weight = \"balanced\", \n",
    "                                max_features = rf_clf.best_estimator_.max_features, \n",
    "                                min_samples_leaf = rf_clf.best_estimator_.min_samples_leaf) \n",
    "rf_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       147                65\n",
      "Actual Negative        23                65\n",
      "\n",
      "Accuracy        0.71\n",
      "AUC             0.78\n",
      "Macro Precision 0.68\n",
      "Macro Recall    0.72\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      212            88\n",
      "Precision    0.86          0.50\n",
      "Recall       0.69          0.74\n",
      "F1           0.77          0.60\n"
     ]
    }
   ],
   "source": [
    "# Score & display performance metrics for test dataset model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = rf_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Performance metrics look good.Large majority of negative (bad credit) cases are identified at expense of significant fp.\n",
    "  # Reported AUC is w/in a std dev of AUC obtained w/ cv, indicating model is generalizing well.\n",
    "    \n",
    "## Summary\n",
    "  # 1) Used random forest model to classify cases of iris data. \n",
    "  #    A model w/ more trees had marginally lower error rates, but likely no significant different.\n",
    "  # 2) Applied feature importance  was used ofr feature selection w/ iris data.\n",
    "  #    Model created & evaluated w/ reduced feature set has essentially the same performance as model w/ more features.\n",
    "  # 3) Used 10 fold to find estimated optimal hyperparameters for random forest model to classify credit cases. Model appears to generalizing well.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
