{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samantha\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Goal: Explore data w/ visualizations for Adventure Works dataset \n",
    "      #    for purpose of Classification Supervised ML w/ label= BikeBuyer\n",
    "\n",
    "# Import Python pkgs pandas, numpy, matplotlib.pyplot, & seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn import cross_validation\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import metrics, cross_validation\n",
    "import scipy.stats as ss\n",
    "import sklearn.decomposition as skde\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "%matplotlib inline  \n",
    "# Start of magic command which configures execution environment, to display graphics w/in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>City</th>\n",
       "      <th>StateProvinceName</th>\n",
       "      <th>CountryRegionName</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PhoneNumber</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>YearlyIncome</th>\n",
       "      <th>Age</th>\n",
       "      <th>AveMonthSpend</th>\n",
       "      <th>BikeBuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jon</td>\n",
       "      <td>Yang</td>\n",
       "      <td>3761 N. 14th St</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4700</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>4/8/1966</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>137947</td>\n",
       "      <td>31</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eugene</td>\n",
       "      <td>Huang</td>\n",
       "      <td>2243 W St.</td>\n",
       "      <td>Seaford</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>3198</td>\n",
       "      <td>1 (11) 500 555-0110</td>\n",
       "      <td>5/14/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>101141</td>\n",
       "      <td>32</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruben</td>\n",
       "      <td>Torres</td>\n",
       "      <td>5844 Linden Land</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7001</td>\n",
       "      <td>1 (11) 500 555-0184</td>\n",
       "      <td>8/12/1965</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91945</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>1825 Village Pl.</td>\n",
       "      <td>North Ryde</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2113</td>\n",
       "      <td>1 (11) 500 555-0162</td>\n",
       "      <td>2/15/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86688</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>7553 Harness Circle</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2500</td>\n",
       "      <td>1 (11) 500 555-0131</td>\n",
       "      <td>8/8/1968</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92771</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstName LastName         AddressLine1         City StateProvinceName  \\\n",
       "0        Jon     Yang      3761 N. 14th St  Rockhampton        Queensland   \n",
       "1     Eugene    Huang           2243 W St.      Seaford          Victoria   \n",
       "2      Ruben   Torres     5844 Linden Land       Hobart          Tasmania   \n",
       "3    Christy      Zhu     1825 Village Pl.   North Ryde   New South Wales   \n",
       "4  Elizabeth  Johnson  7553 Harness Circle   Wollongong   New South Wales   \n",
       "\n",
       "  CountryRegionName PostalCode          PhoneNumber  BirthDate   Education  \\\n",
       "0         Australia       4700  1 (11) 500 555-0162   4/8/1966  Bachelors    \n",
       "1         Australia       3198  1 (11) 500 555-0110  5/14/1965  Bachelors    \n",
       "2         Australia       7001  1 (11) 500 555-0184  8/12/1965  Bachelors    \n",
       "3         Australia       2113  1 (11) 500 555-0162  2/15/1968  Bachelors    \n",
       "4         Australia       2500  1 (11) 500 555-0131   8/8/1968  Bachelors    \n",
       "\n",
       "     ...     Gender MaritalStatus HomeOwnerFlag  NumberCarsOwned  \\\n",
       "0    ...          M             M             1                0   \n",
       "1    ...          M             S             0                1   \n",
       "2    ...          M             M             1                1   \n",
       "3    ...          F             S             0                1   \n",
       "4    ...          F             S             1                4   \n",
       "\n",
       "   NumberChildrenAtHome  TotalChildren  YearlyIncome  Age  AveMonthSpend  \\\n",
       "0                     0              2        137947   31             89   \n",
       "1                     3              3        101141   32            117   \n",
       "2                     3              3         91945   32            123   \n",
       "3                     0              0         86688   29             50   \n",
       "4                     5              5         92771   29             95   \n",
       "\n",
       "   BikeBuyer  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load already prepared dataset, display shape, & explore first 10 rows of Pandas data frame\n",
    "\n",
    "AW_Custs_C = pd.read_csv('AdvWorksCusts_Preped.csv', header=0)\n",
    "print(AW_Custs_C.shape)\n",
    "AW_Custs_C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10949\n",
      "1     5455\n",
      "Name: BikeBuyer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Testing for Class Imbalance by Examining Classes where label= BikeBuyer\n",
    " # Unequal numbers of cases for the categories of labels, which can seriously bias the training of classifier alogrithms \n",
    " #  higher error rate for the minority class. This should be tested for before training any model.   \n",
    "\n",
    "AW_Custs_C_counts =  AW_Custs_C['BikeBuyer'].value_counts()\n",
    "print(AW_Custs_C_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Knowing imbalance exists, the best accuracy we can get w/out creating a ML model is 70%.\n",
    " # This is achieved by guessing all customers will buy a bike\n",
    "    \n",
    "#Below- Create a numpy array of label values\n",
    "\n",
    "labels = np.array(AW_Custs_C['BikeBuyer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 31)\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Create a numpy array with all of the features (Model Matrix)\n",
    " # Encode categorical string variables into integers. \n",
    " # Transform integer coded variables to dummy variables.\n",
    " # Append each dummy coded categorical variable to model matrix.\n",
    "    \n",
    "def encode_string(cat_features):\n",
    "    enc = preprocessing.LabelEncoder()  # Encode strings to numeric categories\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    \n",
    "    ohe = preprocessing.OneHotEncoder()  #Apply One Hot Encoder\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Education', 'Gender', 'MaritalStatus', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren']\n",
    "\n",
    "Features = encode_string(AW_Custs_C['Occupation'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AW_Custs_C[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "    \n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 33)\n",
      "[[0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.37947e+05 3.10000e+01]\n",
      " [0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.01141e+05 3.20000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Append numeric features to model matrix\n",
    "\n",
    "Features = np.concatenate([Features, np.array(AW_Custs_C[['YearlyIncome', 'Age']])], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Professional' 'Management' 'Skilled Manual' 'Clerical' 'Manual']\n"
     ]
    }
   ],
   "source": [
    "# 6 categorical variables were converted into 31 dummy variables. \n",
    "\n",
    "#Below- How many dummy variables came from checking_account_status? -5-\n",
    "print(AW_Custs_C['Occupation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boosting & AdaBoost\n",
    " #Below- Nested cross validation (Ncv) used to estimate optimal hyperparameters & perform model selection for AdaBoost tree model using 10 folds.\n",
    "\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Estimate best hyperparameters using 10 fold cv\n",
    " # 1) Grid of 1 hyperparameter is searched (intended to optimize level of regularization)\n",
    " #   # Learning_rate shrinks contribution of each classifer. THere is a trade-off b/w learning-rate & n_estimators.\n",
    " # 2) Class imbalance is true & difference in cost to bank for misclassification of bad credit risk customers\n",
    "     # will be addressed later.\n",
    " # 3) Model fit on each set of hyperparameters from grid\n",
    " # 4) Best estimated hyperparameters are displayed\n",
    "\n",
    "\n",
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}    ## Define dictionary for grid search & model object to search on\n",
    "\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  ## Define AdaBoosted tree model\n",
    "\n",
    "\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid,    ## Perform grid search over parameters\n",
    "                      cv = inside,          # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(Features, labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.853\n",
      "SDT of the Metric       = 0.009\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.867\n",
      "Fold  2    0.844\n",
      "Fold  3    0.851\n",
      "Fold  4    0.861\n",
      "Fold  5    0.847\n",
      "Fold  6    0.847\n",
      "Fold  7    0.844\n",
      "Fold  8    0.868\n",
      "Fold  9    0.851\n",
      "Fold 10    0.848\n"
     ]
    }
   ],
   "source": [
    "# Perform outer cv of model\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Std dev of mean of AUC is more than an order of manitude smaller than mean, indicating this model will generalize well.\n",
    "\n",
    "#Below- Build & test model using estimated optimal hyperparameters\n",
    "\n",
    "nr.seed(1115)   # Randomly sample cases to create independent training & test data\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define AdaBoosted tree model object using estimated optimal hyperparameter & fit model to training data\n",
    "\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive      2903               414\n",
      "Actual Negative       633              1050\n",
      "\n",
      "Accuracy        0.79\n",
      "AUC             0.85\n",
      "Macro Precision 0.77\n",
      "Macro Recall    0.75\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case     3317          1683\n",
      "Precision    0.82          0.72\n",
      "Recall       0.88          0.62\n",
      "F1           0.85          0.67\n"
     ]
    }
   ],
   "source": [
    "# Score & display performance metrics for test dataset model\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ab_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5455 5455]\n",
      "(10910, 33)\n",
      "(10910,)\n"
     ]
    }
   ],
   "source": [
    "#Above- Performance metrics look good. Large majority of negative (non bike buyers) cases are correctly classified at expense of significant fp.\n",
    "  # This shows AdaBoosted method are sensitive to class imbalance.\n",
    "    \n",
    "#Below- Poor performance is more than likely due to class imbalance & unable to reweigh classes w/ boosting methods. Alternatives:\n",
    " # 1) Impute new values using statistical alogrithm,\n",
    " # 2) Undersample majority of cases. For this method, a # of cases = to minority case are Bernoulli sampled from majority case,\n",
    " # 3) Oversampl minority cases. For this method, a # of minority cases are resampled until = # of majority cases.\n",
    "    \n",
    "# Undersample the majority cases (bike buyers), using choice funtion from Numpy.random package to randomize undersampling.\n",
    " # Count of unique label values & shape of resulting arrays is displayed.\n",
    " # Create data set w/ balanced cases.\n",
    "\n",
    "temp_Labels_1 = labels[labels == 1]         # Save these\n",
    "temp_Features_1 = Features[labels == 1,:]    # Save these\n",
    "temp_Labels_0 = labels[labels == 0]        # Undersample these\n",
    "temp_Features_0 = Features[labels == 0,:]    # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "temp_Features = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "temp_Labels = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(temp_Labels))\n",
    "print(temp_Features.shape)\n",
    "print(temp_Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Above- Now 5455 of each label case w/ 10910 cases overall.\n",
    "\n",
    "#Below- Perform model selection again w/ ncv\n",
    " #Compute inner loop to find optimal learning rate parameter\n",
    "    \n",
    "nr.seed(1234)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(3214)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "ab_clf = AdaBoostClassifier()    # Define AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid,    # Perform grid search over parameters\n",
    "                      cv = inside,                     # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(temp_Features, temp_Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metric = 0.853\n",
      "SDT of the Metric       = 0.009\n",
      "Outcomes by CV Fold\n",
      "Fold  1    0.867\n",
      "Fold  2    0.844\n",
      "Fold  3    0.851\n",
      "Fold  4    0.861\n",
      "Fold  5    0.847\n",
      "Fold  6    0.847\n",
      "Fold  7    0.844\n",
      "Fold  8    0.868\n",
      "Fold  9    0.851\n",
      "Fold 10    0.848\n"
     ]
    }
   ],
   "source": [
    "#Above- Estimated optimal learning rate parameter is sam as before (1).\n",
    "\n",
    "#Below- Perform outer cv of model\n",
    "\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean Performance Metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the Metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by CV Fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5348 5348]\n",
      "(10696, 33)\n",
      "(10696,)\n"
     ]
    }
   ],
   "source": [
    "#Above- Average AUC is improved compared to imbalanced training cases. Differences are w/in 1 std dev. Still reasonable chance represent improvement.\n",
    "\n",
    "#Below- Train & evaluate model w/ balanced cases & updated hyperparameter.\n",
    "  # Create Bernoulli sampled test & training subsets\n",
    "  # Define AdaBoosted model\n",
    "  # Train AdaBoosted model\n",
    "    \n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])   # Randomly sample cases to create independent training & test data\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])\n",
    "\n",
    "# Undersample majority case for training data\n",
    "temp_Labels_1 = y_train[y_train == 1]      # Save these\n",
    "temp_Features_1 = x_train[y_train == 1,:]      # Save these\n",
    "temp_Labels_0 = y_train[y_train == 0]       # Undersample these\n",
    "temp_Features_0 = x_train[y_train == 0,:]     # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "x_train = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "y_train = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define & fit the model\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix\n",
      "                 Score Positive    Score Negative\n",
      "Actual Positive       143                50\n",
      "Actual Negative        25                82\n",
      "\n",
      "Accuracy        0.75\n",
      "AUC             0.85\n",
      "Macro Precision 0.74\n",
      "Macro Recall    0.75\n",
      " \n",
      "           Positive      Negative\n",
      "Num Case      193           107\n",
      "Precision    0.85          0.62\n",
      "Recall       0.74          0.77\n",
      "F1           0.79          0.69\n"
     ]
    }
   ],
   "source": [
    "# Score & evaluate the model\n",
    "\n",
    "probabilities = ab_mod.predict_proba(x_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above- Results are same as previously obtained imbalanced training data in classifying negative cases.\n",
    "  # AUC is approximately the same as ncv AUC.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
